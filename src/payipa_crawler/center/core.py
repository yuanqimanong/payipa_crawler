from functools import wraps

import anyio
import anyio.from_thread
import anyio.to_thread

# å…¨å±€ä»»åŠ¡æ³¨å†Œè¡¨ï¼Œç”¨äºæ¡†æ¶è‡ªåŠ¨å‘ç°ä»»åŠ¡
_REGISTRY = []


class TaskContext:
    """
    ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼šåŒ…è£¹ç”¨æˆ·çš„åŒæ­¥å‡½æ•°ï¼Œå¤„ç†å¼‚æ­¥è°ƒåº¦
    """

    def __init__(self, func, queue_name, max_workers=10):
        self.func = func
        self.queue_name = queue_name
        # å¼‚æ­¥é˜Ÿåˆ— (Buffer)
        self.send_stream, self.receive_stream = anyio.create_memory_object_stream(1000)
        # é™åˆ¶å¹¶å‘æ•°çš„ä¿¡å·é‡ (Bulkheadæ¨¡å¼)
        self.limiter = anyio.Semaphore(max_workers)
        _REGISTRY.append(self)

    def push(self, *args, **kwargs):
        """
        ã€å…³é”®ã€‘è¿™æ˜¯ç»™ç”¨æˆ·è°ƒç”¨çš„åŒæ­¥æ–¹æ³• (Sync API)
        ç”¨æˆ·åœ¨åŒæ­¥å‡½æ•°é‡Œè°ƒç”¨å®ƒï¼Œå®ƒä¼šåœ¨åº•å±‚é€šè¿‡ Portal æ¡¥æ¥åˆ°å¼‚æ­¥å¾ªç¯
        """
        # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šä¸ç®¡è°è°ƒç”¨æˆ‘ï¼Œæˆ‘éƒ½æŠŠå®ƒè½¬äº¤ç»™ AnyIO çš„ä¸»å¾ªç¯å»æ‰§è¡Œ _async_push
        try:
            anyio.from_thread.run(self._async_push, args, kwargs)
        except RuntimeError:
            # å¦‚æœæ˜¯åœ¨ä¸»åç¨‹å¤–éƒ¨è°ƒç”¨ï¼ˆæ¯”å¦‚è„šæœ¬å…¥å£ï¼‰ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†æˆ–æŠ¥é”™ï¼Œ
            # è¿™é‡Œä¸ºäº†Demoç®€å•ï¼Œå‡è®¾éƒ½åœ¨è¿è¡Œæ—¶çš„ä¸Šä¸‹æ–‡æˆ–é€šè¿‡å¤–éƒ¨å…¥å£æ³¨å…¥
            print("âŒ é”™è¯¯ï¼špushå¿…é¡»åœ¨æ¡†æ¶è¿è¡Œä¸Šä¸‹æ–‡ä¸­è°ƒç”¨")

    async def _async_push(self, args, kwargs):
        """å†…éƒ¨çš„å¼‚æ­¥æ¨é€é€»è¾‘"""
        # print(f"    [æ¡†æ¶è°ƒåº¦] ä»»åŠ¡å…¥é˜Ÿ -> {self.queue_name}")
        await self.send_stream.send((args, kwargs))

    async def _worker_loop(self):
        """å†…éƒ¨çš„æ¶ˆè´¹è€…å¾ªç¯"""
        print(f"ğŸ”§ [Worker] å¯åŠ¨ç›‘å¬: {self.queue_name}")
        async for item in self.receive_stream:
            args, kwargs = item
            # è·å–ä¿¡å·é‡ï¼Œé™åˆ¶å¹¶å‘çº¿ç¨‹æ•°
            async with self.limiter:
                # ã€æ ¸å¿ƒé­”æ³•ã€‘æŠŠç”¨æˆ·çš„åŒæ­¥å‡½æ•°æ‰”åˆ°çº¿ç¨‹æ± å»è·‘ï¼Œä¸è¦é˜»å¡æˆ‘çš„å¼‚æ­¥å¾ªç¯ï¼
                # print(f"    [çº¿ç¨‹æ± ] æ­£åœ¨æ‰§è¡Œç”¨æˆ·é€»è¾‘: {self.queue_name}")
                await anyio.to_thread.run_sync(self._execute_user_logic, args, kwargs)

    def _execute_user_logic(self, args, kwargs):
        """åœ¨çº¿ç¨‹ä¸­çœŸæ­£æ‰§è¡Œç”¨æˆ·çš„ä»£ç """
        try:
            self.func(*args, **kwargs)
        except Exception as e:
            print(f"âŒ ç”¨æˆ·ä»£ç æŠ¥é”™ ({self.queue_name}): {e}")

    def attach(self, tg):
        tg.start_soon(self._worker_loop)


def crawler_task(queue_name, max_workers=5):
    """
    è£…é¥°å™¨ï¼šç”¨æˆ·åªçœ‹åˆ°è¿™ä¸ª
    """

    def decorator(func):
        # åˆ›å»º TaskContext å®ä¾‹ä»£æ›¿åŸå‡½æ•°
        task = TaskContext(func, queue_name, max_workers)

        # ä¸ºäº†è®©ç”¨æˆ·èƒ½è°ƒç”¨ func.push()ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¿™ä¸ª wrapper ä¸ŠæŒ‚è½½ push
        @wraps(func)
        def wrapper(*args, **kwargs):
            return func(*args, **kwargs)

        wrapper.push = task.push
        # éšè—å±æ€§ï¼Œæ¡†æ¶ç”¨æ¥å¯åŠ¨
        wrapper._task_context = task
        return wrapper

    return decorator


class SpiderEngine:
    """
    å¼•æ“å…¥å£
    """

    @staticmethod
    def start(backend='trio'):
        print("ğŸš€ å¼•æ“å¯åŠ¨ä¸­...")
        try:
            anyio.run(SpiderEngine._main_entry, backend=backend)
        except KeyboardInterrupt:
            pass

    @staticmethod
    async def _main_entry():
        async with anyio.create_task_group() as tg:
            # 1. è‡ªåŠ¨å‘ç°å¹¶å¯åŠ¨æ‰€æœ‰è¢«è£…é¥°çš„ä»»åŠ¡
            for task_ctx in _REGISTRY:
                task_ctx.attach(tg)

            # 2. ä¿æŒè¿è¡Œ (åœ¨çœŸå®åœºæ™¯ä¸­è¿™é‡Œä¼šæœ‰æ›´å¤æ‚çš„é€€å‡ºæœºåˆ¶)
            # è¿™é‡Œæˆ‘ä»¬é€šè¿‡æ— é™ç­‰å¾…æ¥æ¨¡æ‹Ÿå®ˆæŠ¤è¿›ç¨‹ï¼Œæˆ–è€…ç­‰å¾…é˜Ÿåˆ—ä¸ºç©º
            print("âœ… æ‰€æœ‰ Worker å·²å°±ç»ªï¼Œç­‰å¾…ä»»åŠ¡...")
            while True:
                await anyio.sleep(1)


import time
import random


# from framework import crawler_task, SpiderEngine (å‡è®¾ä¸Šé¢çš„ä»£ç ä¿å­˜ä¸ºframework)

# æ¨¡æ‹Ÿä¸€ä¸ªè§£æä»»åŠ¡
@crawler_task(queue_name="save_db", max_workers=2)
def step_save_data(url, title):
    print(f"ğŸ’¾ [å…¥åº“] æ­£åœ¨å†™å…¥æ•°æ®åº“: {title}...")
    # ç”¨æˆ·å®Œå…¨å¯ä»¥ç”¨é˜»å¡çš„ time.sleep
    time.sleep(0.5)
    print(f"âœ… [å®Œæˆ] {url} æ•°æ®å·²ä¿å­˜")


# æ¨¡æ‹Ÿä¸€ä¸ªä¸‹è½½ä»»åŠ¡
@crawler_task(queue_name="download", max_workers=5)
def step_download(url):
    print(f"ğŸŒ [ä¸‹è½½] å¼€å§‹è¯·æ±‚: {url}")

    # æ¨¡æ‹Ÿç½‘ç»œé˜»å¡ï¼Œç”¨æˆ·ä¸éœ€è¦çŸ¥é“è¿™å°±æ˜¯åœ¨çº¿ç¨‹é‡Œè·‘çš„
    time.sleep(random.uniform(0.5, 1.5))

    # æ¨¡æ‹Ÿè§£æå‡ºäº†æ ‡é¢˜
    title = f"Page Title for {url.split('//')[-1]}"

    # ã€é‡ç‚¹ã€‘ç”¨æˆ·ç›´æ¥è°ƒç”¨ .push()ï¼Œåƒè°ƒç”¨æ™®é€šå‡½æ•°ä¸€æ ·
    # æ¡†æ¶ä¼šåœ¨åº•å±‚æŠŠå®ƒè½¬å›å¼‚æ­¥æ¶ˆæ¯
    step_save_data.push(url, title)


# æ¨¡æ‹Ÿå…¥å£
@crawler_task(queue_name="seed")
def start_requests():
    urls = [f"http://site-{i}.com" for i in range(1, 10)]
    for url in urls:
        step_download.push(url)


# å¯åŠ¨
if __name__ == '__main__':
    # ç”¨æˆ·éœ€è¦åœ¨æŸå¤„æ³¨å…¥ç§å­ä»»åŠ¡
    # ä½†ç”±äºæˆ‘ä»¬çš„ push ä¾èµ– anyio å¾ªç¯è¿è¡Œï¼Œæ‰€ä»¥è¿™é‡Œéœ€è¦ä¸€ç‚¹å°æŠ€å·§ï¼š
    # æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªç‰¹æ®Šçš„â€œå¯åŠ¨é’©å­â€ï¼Œæˆ–è€…ç®€å•åœ°è®©å¼•æ“å¯åŠ¨åï¼Œæˆ‘ä»¬åœ¨å†…éƒ¨è§¦å‘

    # ä¸ºäº†æ¼”ç¤ºç®€å•ï¼Œæˆ‘ä¿®æ”¹ä¸€ä¸‹ Engine çš„å¯åŠ¨é€»è¾‘ï¼Œå…è®¸ä¼ å…¥ä¸€ä¸ª init å‡½æ•°

    async def main_logic():
        # æ‰‹åŠ¨æ³¨å…¥ç§å­ï¼Œæ³¨æ„ï¼šè¿™é‡Œæ˜¯åœ¨ async ä¸Šä¸‹æ–‡ä¸­ï¼Œ
        # å¦‚æœè¦è°ƒç”¨åŒæ­¥çš„ pushï¼Œæˆ‘ä»¬éœ€è¦ç”¨ to_thread æˆ–è€…ç›´æ¥è°ƒç”¨åº•å±‚çš„ _async_push
        # ä¸ºäº†ç»™ç”¨æˆ·â€œå…¨åŒæ­¥â€çš„ä½“éªŒï¼Œæˆ‘ä»¬åœ¨ Engine å†…éƒ¨åšä¸€ä¸ªå¼•å¯¼ä»»åŠ¡å³å¯ã€‚

        # è¿™é‡Œæ¨¡æ‹Ÿç”¨æˆ·é€»è¾‘ä¸­æœ€å¼€å§‹çš„è§¦å‘ï¼š
        # åœ¨æ¡†æ¶å¯åŠ¨çš„ TaskGroup é‡Œï¼Œæˆ‘ä»¬ä¸“é—¨å¼€ä¸€ä¸ªåç¨‹æ¥è¿è¡Œ start_requests
        await anyio.to_thread.run_sync(start_requests)


    # ç¨å¾®ä¿®æ”¹ä¸€ä¸‹ Engine ä»¥æ”¯æŒè¿™ä¸ª Demo çš„å¯åŠ¨æ–¹å¼
    # åœ¨çœŸå®æ¡†æ¶ä¸­ï¼Œè¿™éƒ¨åˆ†é€šå¸¸å°è£…åœ¨ Engine.start(seed_task=start_requests)

    print("--- ç”¨æˆ·è„šæœ¬å¼€å§‹ ---")


    async def boot():
        async with anyio.create_task_group() as tg:
            # 1. å¯åŠ¨æ‰€æœ‰é˜Ÿåˆ—ç›‘å¬
            for task_ctx in _REGISTRY:
                task_ctx.attach(tg)

            # 2. å¯åŠ¨ç§å­ä»»åŠ¡ (åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼Œä¸é˜»å¡ä¸»å¾ªç¯)
            tg.start_soon(anyio.to_thread.run_sync, start_requests)


    anyio.run(boot, backend='trio')
